{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "59cec704-d1d3-4ebd-b3f7-27b0db464f17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "DATA INGESTION and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d647081-9534-4d28-9e07-3495aec23af5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Convert Date column to proper format\n",
    "Use PySpark SQL functions to modularly change all existing tables to the correct date format. Had to be done because SQLSpark doesn't allow UPDATEs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a579804-bbb9-469e-a5fa-5f1b5415ff70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizing date for amazon dataframe\n+----------+------+------+------+------+---------+\n|      date|  open|  high|   low| close|   volume|\n+----------+------+------+------+------+---------+\n|1997-05-16| 0.093|0.0987|0.0852|0.0863|294000000|\n|1997-05-19|0.0852|0.0883|0.0811|0.0852|122136000|\n|1997-05-20|0.0863|0.0873|0.0816|0.0816|109344000|\n|1997-05-21|  0.08|0.0821|0.0686|0.0712|377064000|\n|1997-05-22|0.0717|0.0722|0.0655|0.0696|235536000|\n|1997-05-23|0.0702|0.0759|0.0665|0.0748|318744000|\n|1997-05-27|0.0738|0.0821|0.0727| 0.079|173952000|\n|1997-05-28|0.0803|0.0816|0.0764|0.0764| 91488000|\n|1997-05-29|0.0769|0.0769|0.0738|0.0751| 69456000|\n|1997-05-30|0.0748|0.0754|0.0738|0.0748| 51888000|\n|1997-06-02|0.0754|0.0764|0.0748|0.0754| 11832000|\n|1997-06-03|0.0764|0.0764|0.0738|0.0738| 23664000|\n|1997-06-04|0.0738|0.0743|0.0696|0.0707| 61608000|\n|1997-06-05|0.0707|0.0769|0.0686|0.0769|113448000|\n|1997-06-06|0.0754|0.0852|0.0754|0.0826|156144000|\n|1997-06-09|0.0842|0.0852|0.0826|0.0842| 47040000|\n|1997-06-10|0.0852|0.0852|0.0764| 0.079|109176000|\n|1997-06-11|0.0795|  0.08|0.0764|0.0769| 23760000|\n|1997-06-12| 0.079|0.0821|0.0774|  0.08| 32640000|\n|1997-06-13|0.0811|0.0811| 0.079| 0.079| 13872000|\n+----------+------+------+------+------+---------+\nonly showing top 20 rows\n\nroot\n |-- date: date (nullable = true)\n |-- open: float (nullable = true)\n |-- high: float (nullable = true)\n |-- low: float (nullable = true)\n |-- close: float (nullable = true)\n |-- volume: long (nullable = true)\n\nnormalizing date for tesla dataframe\n+----------+------+------+------+------+---------+\n|      date|  open|  high|   low| close|   volume|\n+----------+------+------+------+------+---------+\n|2010-06-29|1.2667|1.6667|1.1693|1.5927|281494500|\n|2010-06-30|1.7193|2.0279|1.5533|1.5887|257806500|\n|2010-07-01|1.6667| 1.728|1.3513| 1.464|123282000|\n|2010-07-02|1.5333|  1.54|1.2473|  1.28| 77097000|\n|2010-07-06|1.3333|1.3333|1.0553| 1.074|103003500|\n|2010-07-07|1.0933|1.1087|0.9987|1.0533|103825500|\n|2010-07-08| 1.076| 1.168| 1.038| 1.164|115671000|\n|2010-07-09| 1.172|1.1933|1.1033|  1.16| 60759000|\n|2010-07-12|1.1967|1.2047|1.1333|1.1367| 33037500|\n|2010-07-13|1.1596|1.2427|1.1267|1.2093| 40201500|\n|2010-07-14| 1.196|1.3433| 1.184|1.3227| 62928000|\n|2010-07-15|1.3293|1.4333|1.2667| 1.326| 56097000|\n|2010-07-16|  1.38|  1.42|1.3367| 1.376| 39319500|\n|2010-07-19|1.4247|1.4833|1.3947|1.4607| 37297500|\n|2010-07-20|1.4567|1.4567|1.3367|1.3533| 27379500|\n|2010-07-21|1.3773|1.3933|   1.3| 1.348| 18787500|\n|2010-07-22|1.3667|1.4167| 1.358|   1.4| 14367000|\n|2010-07-23|1.4127|1.4373| 1.404|1.4193|  9804000|\n|2010-07-26|1.4333|1.4333|1.3533|1.3967| 13833000|\n|2010-07-27| 1.394| 1.412|1.3507|  1.37|  9295500|\n+----------+------+------+------+------+---------+\nonly showing top 20 rows\n\nroot\n |-- date: date (nullable = true)\n |-- open: float (nullable = true)\n |-- high: float (nullable = true)\n |-- low: float (nullable = true)\n |-- close: float (nullable = true)\n |-- volume: long (nullable = true)\n\nnormalizing date for apple dataframe\n+----------+------+------+------+------+---------+\n|      date|  open|  high|   low| close|   volume|\n+----------+------+------+------+------+---------+\n|1980-12-12|0.0991|0.0995|0.0991|0.0991|469033600|\n|1980-12-15|0.0944|0.0944|0.0939|0.0939|175884800|\n|1980-12-16|0.0874|0.0874| 0.087| 0.087|105728000|\n|1980-12-17|0.0892|0.0896|0.0892|0.0892| 86441600|\n|1980-12-18|0.0918|0.0922|0.0918|0.0918| 73449600|\n|1980-12-19|0.0974|0.0978|0.0974|0.0974| 48630400|\n|1980-12-22|0.1021|0.1025|0.1021|0.1021| 37363200|\n|1980-12-23|0.1064|0.1068|0.1064|0.1064| 46950400|\n|1980-12-24| 0.112|0.1125| 0.112| 0.112| 48003200|\n|1980-12-26|0.1223|0.1228|0.1223|0.1223| 55574400|\n|1980-12-29|0.1241|0.1245|0.1241|0.1241| 93161600|\n|1980-12-30|0.1215|0.1215| 0.121| 0.121| 68880000|\n|1980-12-31| 0.118| 0.118|0.1176|0.1176| 35750400|\n|1981-01-02|0.1189|0.1198|0.1189|0.1189| 21660800|\n|1981-01-05|0.1167|0.1167|0.1163|0.1163| 35728000|\n|1981-01-06|0.1116|0.1116|0.1111|0.1111| 45158400|\n|1981-01-07|0.1068|0.1068|0.1064|0.1064| 55686400|\n|1981-01-08|0.1047|0.1047|0.1043|0.1043| 39827200|\n|1981-01-09|0.1099|0.1103|0.1099|0.1099| 21504000|\n|1981-01-12|0.1099|0.1099| 0.109| 0.109| 23699200|\n+----------+------+------+------+------+---------+\nonly showing top 20 rows\n\nroot\n |-- date: date (nullable = true)\n |-- open: float (nullable = true)\n |-- high: float (nullable = true)\n |-- low: float (nullable = true)\n |-- close: float (nullable = true)\n |-- volume: long (nullable = true)\n\nnormalizing date for microsoft dataframe\n+----------+------+------+------+------+----------+\n|      date|  open|  high|   low| close|    volume|\n+----------+------+------+------+------+----------+\n|1986-03-13|0.0548|0.0628|0.0548|0.0602|1031788800|\n|1986-03-14|0.0602|0.0634|0.0602|0.0623| 308160000|\n|1986-03-17|0.0623|0.0639|0.0623|0.0634| 133171200|\n|1986-03-18|0.0634|0.0639|0.0612|0.0618|  67766400|\n|1986-03-19|0.0618|0.0623|0.0602|0.0607|  47894400|\n|1986-03-20|0.0607|0.0607|0.0585|0.0591|  58435200|\n|1986-03-21|0.0591|0.0602|0.0564|0.0575|  59990400|\n|1986-03-24|0.0575|0.0575|0.0553|0.0559|  65289600|\n|1986-03-25|0.0559|0.0569|0.0553|0.0569|  32083200|\n|1986-03-26|0.0569|0.0591|0.0564|0.0585|  22752000|\n|1986-03-27|0.0585|0.0596|0.0585|0.0596|  16848000|\n|1986-03-31|0.0596|0.0596| 0.058|0.0591|  12873600|\n|1986-04-01|0.0591|0.0591|0.0585|0.0585|  11088000|\n|1986-04-02|0.0585|0.0602|0.0585|0.0591|  27014400|\n|1986-04-03|0.0596|0.0612|0.0596|0.0596|  23040000|\n|1986-04-04|0.0596|0.0602|0.0596|0.0596|  26582400|\n|1986-04-07|0.0596|0.0602|0.0575|0.0585|  16560000|\n|1986-04-08|0.0585|0.0602|0.0585|0.0591|  10252800|\n|1986-04-09|0.0591|0.0607|0.0591|0.0602|  12153600|\n|1986-04-10|0.0602|0.0612|0.0591|0.0607|  13881600|\n+----------+------+------+------+------+----------+\nonly showing top 20 rows\n\nroot\n |-- date: date (nullable = true)\n |-- open: float (nullable = true)\n |-- high: float (nullable = true)\n |-- low: float (nullable = true)\n |-- close: float (nullable = true)\n |-- volume: long (nullable = true)\n\nnormalizing date for eli_lily dataframe\n+----------+------+------+------+------+-------+\n|      date|  open|  high|   low| close| volume|\n+----------+------+------+------+------+-------+\n|1972-06-01|1.4725|1.4746|1.4578|1.4662| 456000|\n|1972-06-02|1.4691|1.4832|1.4691|1.4832| 640000|\n|1972-06-05|1.4805|1.4805|1.4578|1.4632| 464000|\n|1972-06-06|1.4632|1.4632|1.4492|1.4492| 796800|\n|1972-06-07|1.4492|1.4691|1.4465|1.4662| 584000|\n|1972-06-08|1.4662|1.4718|1.4465|1.4492| 726400|\n|1972-06-09|1.4519|1.4691|1.4519|1.4662| 296000|\n|1972-06-12|1.4662|1.4775|1.4549|1.4632| 473600|\n|1972-06-13|1.4662|1.4832|1.4662|1.4775| 478400|\n|1972-06-14|1.4832|1.5144|1.4832|1.5085| 795200|\n|1972-06-15|1.5171|1.5341|1.5171|1.5171| 836800|\n|1972-06-16|1.5171|1.5199|1.4945|1.5002| 267200|\n|1972-06-19|1.5002|1.5085|1.4718|1.4888|1001600|\n|1972-06-20|1.4945|1.5085|1.4945|1.5085| 345600|\n|1972-06-21|1.5085|1.5144|1.4918|1.4945| 556800|\n|1972-06-22|1.4945|1.5085|1.4888|1.5058| 321600|\n|1972-06-23|1.5058|1.5144|1.5058|1.5115| 212800|\n|1972-06-26|1.5115|1.5285|1.4972|1.5285| 278400|\n|1972-06-27|1.5285|1.5371|1.5115|1.5199| 268800|\n|1972-06-28|1.5144|1.5144|1.4888|1.4945| 433600|\n+----------+------+------+------+------+-------+\nonly showing top 20 rows\n\nroot\n |-- date: date (nullable = true)\n |-- open: float (nullable = true)\n |-- high: float (nullable = true)\n |-- low: float (nullable = true)\n |-- close: float (nullable = true)\n |-- volume: long (nullable = true)\n\nnormalizing date for united_health dataframe\n+----------+------+------+------+------+-------+\n|      date|  open|  high|   low| close| volume|\n+----------+------+------+------+------+-------+\n|1990-03-26|0.2344|0.2344|0.2315|0.2315| 412800|\n|1990-03-27|0.2315|0.2435|0.2315|0.2435|3913600|\n|1990-03-28|0.2435|0.2435|0.2374|0.2374|1561600|\n|1990-03-29|0.2435|0.2435|0.2406|0.2406| 537600|\n|1990-03-30|0.2435|0.2435|0.2374|0.2406|1756800|\n|1990-04-02|0.2374|0.2435|0.2315|0.2435|2451200|\n|1990-04-03|0.2468|0.2529|0.2406|0.2468|2812800|\n|1990-04-04|  0.25|0.2529|0.2435|0.2468|4003200|\n|1990-04-05|  0.25|0.2561|  0.25|0.2529|3961600|\n|1990-04-06|0.2561|0.2591|0.2529|0.2561|1273600|\n|1990-04-09|0.2561|0.2591|  0.25|  0.25|2873600|\n|1990-04-10|  0.25|0.2529|0.2435|0.2435|2118400|\n|1990-04-11|  0.25|0.2529|0.2468|  0.25|3440000|\n|1990-04-12|0.2529|0.2591|  0.25|0.2591|3254400|\n|1990-04-16|0.2591| 0.262|0.2529|0.2561|4595200|\n|1990-04-17|0.2561| 0.262|0.2561|0.2561|7257600|\n|1990-04-18|0.2561|0.2591|0.2529|0.2529|2291200|\n|1990-04-19|0.2529|0.2529|  0.25|0.2529| 896000|\n|1990-04-20|  0.25|0.2529|0.2468|  0.25|1168000|\n|1990-04-23|0.2435|0.2468|0.2406|0.2468| 998400|\n+----------+------+------+------+------+-------+\nonly showing top 20 rows\n\nroot\n |-- date: date (nullable = true)\n |-- open: float (nullable = true)\n |-- high: float (nullable = true)\n |-- low: float (nullable = true)\n |-- close: float (nullable = true)\n |-- volume: long (nullable = true)\n\nnormalizing date for berkshire_b dataframe\n+----------+-----+----+----+-----+-------+\n|      date| open|high| low|close| volume|\n+----------+-----+----+----+-----+-------+\n|1996-05-09| 23.6|24.0|23.1| 23.2| 580000|\n|1996-05-10| 24.0|24.2|23.6| 24.0|1060000|\n|1996-05-13| 24.0|24.1|23.3| 23.9| 700000|\n|1996-05-14| 24.0|24.1|23.1| 23.6| 310000|\n|1996-05-15| 23.6|23.7|23.0| 23.2| 545000|\n|1996-05-16| 23.1|23.1|22.3| 22.6| 360000|\n|1996-05-17| 22.6|23.0|22.6| 22.8| 325000|\n|1996-05-20| 22.9|23.0|22.4| 22.5| 240000|\n|1996-05-21| 22.7|22.8|22.3| 22.6| 235000|\n|1996-05-22| 22.7|22.7|21.8| 22.0| 250000|\n|1996-05-23| 22.0|22.2|21.7| 22.1| 205000|\n|1996-05-24| 22.1|22.1|21.4| 21.6| 155000|\n|1996-05-28| 21.9|22.1|21.2| 21.2| 205000|\n|1996-05-29| 21.0|21.3|20.7| 20.8| 105000|\n|1996-05-30| 20.7|20.8|20.0| 20.5| 320000|\n|1996-05-31| 20.2|20.4|19.8| 20.4| 230000|\n|1996-06-03| 20.4|20.5|20.0| 20.1|  80000|\n|1996-06-04| 20.1|21.4|20.1| 21.4| 115000|\n|1996-06-05| 21.4|22.0|21.3|21.86| 165000|\n|1996-06-06|21.86|22.0|21.7| 21.7|  90000|\n+----------+-----+----+----+-----+-------+\nonly showing top 20 rows\n\nroot\n |-- date: date (nullable = true)\n |-- open: float (nullable = true)\n |-- high: float (nullable = true)\n |-- low: float (nullable = true)\n |-- close: float (nullable = true)\n |-- volume: long (nullable = true)\n\nnormalizing date for jp_morgan dataframe\n+----------+------+------+------+------+-------+\n|      date|  open|  high|   low| close| volume|\n+----------+------+------+------+------+-------+\n|1983-12-30|2.5221|2.5508|2.4935|2.5221| 211500|\n|1984-01-03|2.5187|2.5365|2.5004|2.5221| 385502|\n|1984-01-04|2.5703|2.6293|2.5365|2.6293| 292500|\n|1984-01-05|2.6832|2.7159|2.6511|2.7159| 344102|\n|1984-01-06|2.6872|2.7159|2.6586|2.6872| 194400|\n|1984-01-09|2.6941|2.7159|2.6723|2.6941| 216302|\n|1984-01-10|2.7337|2.7658| 2.701|2.7445| 143100|\n|1984-01-11|2.7445|2.8087|2.7159|2.8013| 397800|\n|1984-01-12|2.8013|2.8449|2.7875|  2.83| 297900|\n|1984-01-13|2.8586|2.8804|2.8374|2.8449| 591300|\n|1984-01-16|  2.83|2.8449|2.8162|2.8162| 103802|\n|1984-01-17|2.8162|2.8162|2.7514|2.7658| 134100|\n|1984-01-18|2.8053|2.8374|2.7732|  2.83|1352700|\n|1984-01-19|  2.83|2.8449|2.8162|  2.83| 245102|\n|1984-01-20|  2.83|  2.83|2.7944|2.8087| 168300|\n|1984-01-23| 2.834|2.8517|2.8162|2.8449| 246002|\n|1984-01-24|2.8626|2.8804|2.8449|2.8804| 292500|\n|1984-01-25|2.9199|2.9377|2.9016|2.9091| 243000|\n|1984-01-26|2.9091|2.9165|2.8735|2.8804| 212400|\n|1984-01-27|2.8804|2.8804|2.8449|2.8661| 183002|\n+----------+------+------+------+------+-------+\nonly showing top 20 rows\n\nroot\n |-- date: date (nullable = true)\n |-- open: float (nullable = true)\n |-- high: float (nullable = true)\n |-- low: float (nullable = true)\n |-- close: float (nullable = true)\n |-- volume: long (nullable = true)\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, to_date, date_format\n",
    "\n",
    "# Store Spark tables directly in the dictionary to avoid issues with scope\n",
    "dataframes = {\n",
    "    'amazon': spark.table('financial_sectors.default.amazon'),\n",
    "    'tesla': spark.table('financial_sectors.default.tesla'),\n",
    "    'apple': spark.table('financial_sectors.default.apple'),\n",
    "    'microsoft': spark.table('financial_sectors.default.microsoft'),\n",
    "    'eli_lily': spark.table('financial_sectors.default.eli_lily'),\n",
    "    'united_health': spark.table('financial_sectors.default.united_health'),\n",
    "    'berkshire_b': spark.table('financial_sectors.default.berkshire_b'),\n",
    "    'jp_morgan': spark.table('financial_sectors.default.jp_morgan'),\n",
    "}\n",
    "\n",
    "# function to format date and change type\n",
    "def normalize_date(column_name,data_frame):\n",
    "        if column_name in data_frame.columns:\n",
    "                # format uniform date column\n",
    "                data_frame = data_frame.withColumn(column_name, date_format(to_date(col(column_name),'M/d/yyyy'),'MM/dd/yyyy'))\n",
    "                # change data type back to date\n",
    "                data_frame = data_frame.withColumn(column_name,to_date(column_name,'MM/dd/yyyy'))\n",
    "                return  data_frame\n",
    "\n",
    "for key in dataframes.keys():\n",
    "        print(f\"normalizing date for {key} dataframe\")\n",
    "        dataframes[key] = normalize_date('date',dataframes[key])\n",
    "        # dataframes[key].show()\n",
    "        # dataframes[key].printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "577f6fee-9c8a-4eac-bb56-f18cffb434f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Additional cleaning\n",
    "Check for and remove null values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "daadf97b-2f43-4d20-8cd3-245c522fc826",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>date</th><th>open</th><th>high</th><th>low</th><th>close</th><th>volume</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         0,
         0,
         0,
         0,
         0,
         0
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "date",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "open",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "high",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "low",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "close",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "volume",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%python\n",
    "# from pyspark.sql.functions import col, sum\n",
    "\n",
    "null_counts = dataframes['amazon'].select(\n",
    "    [sum(col(c).isNull().cast(\"int\")).alias(c) for c in dataframes['amazon'].columns]\n",
    ")\n",
    "display(null_counts)\n",
    "# taken from the assistant just because it worked right away.\n",
    "# col(c): This function creates a column object for the column name c.\n",
    "# col(c).isNull(): This checks if the column value is null.\n",
    "# col(c).isNull().cast(\"int\"): This casts the boolean result of isNull() to an integer (1 for null, 0 for non-null).\n",
    "# sum(col(c).isNull().cast(\"int\")): This sums up the integer values, effectively counting the number of nulls in the column.\n",
    "# .alias(c): This gives the resulting column the same name as the original column.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15974561-7186-44e2-9754-7ce262b89aa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### DataFrame is ready to overwrite existing tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "47fa8617-583a-4308-89a6-912a23ecff11",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for key in dataframes.keys():\n",
    "    dataframes[key].write.mode('overwrite').saveAsTable(f'{key}_cleaned')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28184162-8f73-4362-91da-add39229202a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Initial Ingestion Complete"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4356275637221647,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Initial Ingestion Work",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}